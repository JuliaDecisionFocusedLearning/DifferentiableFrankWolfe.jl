var documenterSearchIndex = {"docs":
[{"location":"#DifferentiableFrankWolfe","page":"Home","title":"DifferentiableFrankWolfe","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for DifferentiableFrankWolfe.jl.","category":"page"},{"location":"#Public-API","page":"Home","title":"Public API","text":"","category":"section"},{"location":"#DifferentiableFrankWolfe.DifferentiableFrankWolfe","page":"Home","title":"DifferentiableFrankWolfe.DifferentiableFrankWolfe","text":"DifferentiableFrankWolfe\n\nDifferentiable wrapper for FrankWolfe.jl convex optimization routines.\n\n\n\n\n\n","category":"module"},{"location":"#DifferentiableFrankWolfe.DiffFW","page":"Home","title":"DifferentiableFrankWolfe.DiffFW","text":"DiffFW\n\nCallable parametrized wrapper for the Frank-Wolfe algorithm to solve θ -> argmin_{x ∈ C} f(x, θ) from a given starting point x0. The solution routine can be differentiated implicitly with respect θ, but not with respect to x0.\n\nConstructor\n\nDiffFW(f, f_grad1, lmo, alg=away_frank_wolfe; step_size=1, implicit_kwargs=(;))\n\nf: function f(x, θ) to minimize with respect to x\nf_grad1: gradient ∇ₓf(x, θ) of f with respect to x\nlmo: linear minimization oracle θ -> argmin_{x ∈ C} θᵀx from FrankWolfe.jl, implicitly defines the convex set C\nalg: optimization algorithm from FrankWolfe.jl, must return an active_set\nstep_size: positive value used to scale the gradient in the Frank-Wolfe optimality condition framed as projected gradient stationarity\nimplicit_kwargs: keyword arguments passed to the ImplicitFunction object from ImplicitDifferentiation.jl\n\nReferences\n\nEfficient and Modular Implicit Differentiation, Blondel et al. (2022)\n\n\n\n\n\n","category":"type"},{"location":"#DifferentiableFrankWolfe.DiffFW-Tuple{AbstractArray, AbstractArray}","page":"Home","title":"DifferentiableFrankWolfe.DiffFW","text":"(dfw::DiffFW)(θ::AbstractArray, x0::AbstractArray; kwargs...)\n\nApply the differentiable Frank-Wolfe algorithm defined by dfw to parameter θ with starting point x0. Keyword arguments are passed on to the Frank-Wolfe algorithm inside dfw.\n\nReturn the optimal solution x.\n\n\n\n\n\n","category":"method"},{"location":"#Private-API","page":"Home","title":"Private API","text":"","category":"section"},{"location":"#DifferentiableFrankWolfe.ConditionsFW","page":"Home","title":"DifferentiableFrankWolfe.ConditionsFW","text":"ConditionsFW\n\nDifferentiable optimality conditions for DiffFW, which rely on a custom simplex_projection implementation.\n\n\n\n\n\n","category":"type"},{"location":"#DifferentiableFrankWolfe.ForwardFW","page":"Home","title":"DifferentiableFrankWolfe.ForwardFW","text":"ForwardFW\n\nUnderlying solver for DiffFW, which relies on a variant of Frank-Wolfe with active set memorization.\n\n\n\n\n\n","category":"type"},{"location":"#DifferentiableFrankWolfe.detailed_output-Tuple{DiffFW, AbstractArray, AbstractArray}","page":"Home","title":"DifferentiableFrankWolfe.detailed_output","text":"detailed_output(dfw::DiffFW, θ::AbstractArray, x0::AbstractArray; kwargs...)\n\nApply the differentiable Frank-Wolfe algorithm defined by dfw to parameter θ with starting point x0. Keyword arguments are passed on to the Frank-Wolfe algorithm inside dfw.\n\nReturn a couple (x, stats) where x is the solution and stats is a named tuple containing additional information (its contents are not covered by public API, and mostly useful for debugging).\n\n\n\n\n\n","category":"method"},{"location":"#DifferentiableFrankWolfe.simplex_projection-Tuple{AbstractVector{<:Real}}","page":"Home","title":"DifferentiableFrankWolfe.simplex_projection","text":"simplex_projection(z)\n\nCompute the Euclidean projection of the vector z onto the probability simplex.\n\nThis function is differentiable thanks to a custom chain rule.\n\nReferences\n\nFrom Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification, Martins and Astudillo (2016)\n\n\n\n\n\n","category":"method"},{"location":"tutorial/#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Necessary imports","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using DifferentiableFrankWolfe: DiffFW, simplex_projection\nusing ForwardDiff: ForwardDiff\nusing FrankWolfe: ProbabilitySimplexLMO\nusing ProximalOperators: ProximalOperators\nusing Test: @test\nusing Zygote: Zygote","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Constructing the wrapper","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"f(x, θ) = 0.5 * sum(abs2, x - θ)  # minimizing the squared distance...\nf_grad1(x, θ) = x - θ\nlmo = ProbabilitySimplexLMO(1.0)  # ... to the probability simplex\ndfw = DiffFW(f, f_grad1, lmo);  # ... is equivalent to a simplex projection if we're not already in it\nnothing #hide","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Calling the wrapper","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"x0 = ones(3) ./ 3\nθ = [1.0, 1.5, 0.2]","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"frank_wolfe_kwargs = (; max_iteration = 100, epsilon = 1.0e-4)\ny = dfw(θ, x0; frank_wolfe_kwargs...)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"true_simplex_projection(x) = ProximalOperators.prox(ProximalOperators.IndSimplex(1.0), x)[1]","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"y_true = true_simplex_projection(θ)\n@test Vector(y) ≈ Vector(y_true) atol = 1.0e-3","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Differentiating the wrapper","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"J_true = ForwardDiff.jacobian(true_simplex_projection, θ)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"J1 = Zygote.jacobian(_θ -> dfw(_θ, x0; frank_wolfe_kwargs...), θ)[1]\n@test J1 ≈ J_true atol = 1.0e-3","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"J2 = ForwardDiff.jacobian(_θ -> dfw(_θ, x0; frank_wolfe_kwargs...), θ)\n@test J2 ≈ J_true atol = 1.0e-3","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This page was generated using Literate.jl.","category":"page"}]
}
